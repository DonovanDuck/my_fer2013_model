{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# kaggle上的一个表情识别\n",
    "（具体资料链接，见文末扩展资料）\n",
    "\n",
    "\n",
    "\n",
    "数据形式：CSV存储，第一个是label，第二个是数据，第三个是阶段\n",
    "\n",
    "网络：\n",
    "用了两种网络，lenet-5改和CliqueNet，后者特殊一些。\n",
    "\n",
    "数据预处理是有用的尝试，将脸居中等.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 整个工程的代码结构\n",
    "fer_forward.py\n",
    "lenet变体的网络参数和结构定义\n",
    "\n",
    "fer_backward.py\n",
    "训练网络\n",
    "\n",
    "fer_generator.py\n",
    "把csv数据集用tfrecord处理\n",
    "\n",
    "fer_config.py\n",
    "各种路径的配置，这个需要自己定制\n",
    "\n",
    "fer_test.py\n",
    "测试网络\n",
    "\n",
    "fer_app.py\n",
    "预处理图片，restore网络并且预测结果\n",
    "\n",
    "cliquenet.py\n",
    "另一个网络结构，暂且不表\n",
    "\n",
    "<b>下面修改调试起来，因为ipynb有引用问题，加上文件众多，所以代码在*.py改，在此处测试，原始文件可以参考下载路径，或在上层目录寻找'../fer2013'。</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他各种ipynb\n",
    "基本都是对各个文件和过程的分解和调试\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把每一部分都单独开一个笔记，下边的不继续了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fer_forward     lenet5变体网络结构定义\n",
    "\n",
    "dropout只有0.95，不是很追求泛化的一个数值\n",
    "\n",
    "lenet-5是7层网络，两个Conv+pooling循环，两个FC，一个OUTPUT。\n",
    "改成9层网络，加了一个conv+pooling循环。卷积核还是5.\n",
    "都是5*5的核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要预处理数据，生成tfrecord\n",
    "import fer_generator\n",
    "import fer_forward\n",
    "import fer_backward\n",
    "import fer_config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fer_generator.devide_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#待会计算一下，看看他输入是什么样，对应输入的每层的情况算一下，因为他的第三个conv提升了通道数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#原图需要处理成单通道，lenet的input是单通道的。\n",
    "\n",
    "fer_backward.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mfer2013\u001b[0m/  \u001b[01;34mFERPlus\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls '/home/qw/Documents/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 读取tfrecord生成信息队列的测试。\n",
    "## 没有对应文件的情况\n",
    "只是想测一下地址为空的时候的反馈\n",
    "看来这么一点小操作都听繁琐的，照猫画虎全程不犯错很难把工程弄的很透。\n",
    "这里主要问题就是，如果你没有tfrecord，地址对应的文件没有，直接训练，不会有任何报错。\n",
    "尝试方法1:直接把tensor拿到，sess.run，结果不行，因为是要用一个producer的，现在等于阻塞了，producer没跑起来。必须启动线程协调器才能得到NotFoundError错误提示，那个producer自己动不起来，启动线程协调器就行了，不用显式的调用producer本身，也类似扔到一个集合，自动给启动了吧，更细的说明，官方没给出，只能看实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.data_flow_ops.FIFOQueue object at 0x7f90430429e8>\n",
      "reader: <tensorflow.python.ops.io_ops.TFRecordReader object at 0x7f9043044a58>\n",
      "Tensor(\"ReaderReadV2:1\", shape=(), dtype=string)\n",
      "{'img_raw': <tf.Tensor 'ParseSingleExample/Squeeze_img_raw:0' shape=() dtype=string>, 'label': <tf.Tensor 'ParseSingleExample/Squeeze_label:0' shape=(7,) dtype=int64>}\n",
      "Tensor(\"mul:0\", shape=(2304,), dtype=float32)\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/home/qw/Documents/datasets/fer2013/fer2013_train.tfrecords\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\nCaused by op 'ReaderReadV2', defined at:\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5497a435f4b3>\", line 19, in <module>\n    _,serialized_example = reader.read(filename_queue)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/io_ops.py\", line 193, in read\n    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 400, in _reader_read_v2\n    queue_handle=queue_handle, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): /home/qw/Documents/datasets/fer2013/fer2013_train.tfrecords\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /home/qw/Documents/datasets/fer2013/fer2013_train.tfrecords\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5497a435f4b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# 启动入队线程\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /home/qw/Documents/datasets/fer2013/fer2013_train.tfrecords\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\nCaused by op 'ReaderReadV2', defined at:\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5497a435f4b3>\", line 19, in <module>\n    _,serialized_example = reader.read(filename_queue)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/io_ops.py\", line 193, in read\n    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 400, in _reader_read_v2\n    queue_handle=queue_handle, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): /home/qw/Documents/datasets/fer2013/fer2013_train.tfrecords\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#随便拿几个数据试一下没tfrecord文件时接口的反馈\n",
    "#tf.train.shuffle_batch阻塞的，没什么反馈,\n",
    "# img_batch, label_batch = fer_generator.get_tfrecord(10,config.tfRecord_train)\n",
    "#只拿tensor，不过shuffle，都是阻塞，太不友好。。。。。。。\n",
    "#img, label = fer_generator.get_tfrecord0(10,config.tfRecord_train)\n",
    "# print(img)\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(img))\n",
    "#     print(sess.run(label))\n",
    "\n",
    "\n",
    "#因为read_tfRecord是要走string_input_producer的\n",
    "filename_queue = tf.train.string_input_producer([config.tfRecord_train])\n",
    "print(filename_queue)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "print('reader:',reader)\n",
    "_,serialized_example = reader.read(filename_queue)\n",
    "print(serialized_example)\n",
    "features = tf.parse_single_example(serialized_example,\n",
    "                                   features={\n",
    "                                       'label':tf.FixedLenFeature([7],tf.int64),\n",
    "                                       'img_raw':tf.FixedLenFeature([],tf.string)\n",
    "                                             })\n",
    "print(features)\n",
    "img = tf.decode_raw(features['img_raw'],tf.uint8)\n",
    "img.set_shape([config.img_height * config.img_height])\n",
    "\n",
    "img = tf.cast(img,tf.float32)*(1./255)\n",
    "label = tf.cast(features['label'],tf.float32)\n",
    "print(img)\n",
    "with tf.Session() as sess:\n",
    "    #直接运行阻塞\n",
    "#     print(sess.run(img))\n",
    "#     print(sess.run(label))\n",
    "\n",
    "    # 创建一个线程协调器\n",
    "    coord=tf.train.Coordinator()\n",
    "    # 启动入队线程\n",
    "    threads=tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    print(sess.run(img))\n",
    "    print(sess.run(label))  \n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "#这样就可以得到错误提示了\n",
    "# NotFoundError: /home/qw/Documents/datasets/fer2013/fer2013_train.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function string_input_producer in module tensorflow.python.training.input:\n",
      "\n",
      "string_input_producer(string_tensor, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None, cancel_op=None)\n",
      "    Output strings (e.g. filenames) to a queue for an input pipeline.\n",
      "    \n",
      "    Note: if `num_epochs` is not `None`, this function creates local counter\n",
      "    `epochs`. Use `local_variables_initializer()` to initialize local variables.\n",
      "    \n",
      "    Args:\n",
      "      string_tensor: A 1-D string tensor with the strings to produce.\n",
      "      num_epochs: An integer (optional). If specified, `string_input_producer`\n",
      "        produces each string from `string_tensor` `num_epochs` times before\n",
      "        generating an `OutOfRange` error. If not specified,\n",
      "        `string_input_producer` can cycle through the strings in `string_tensor`\n",
      "        an unlimited number of times.\n",
      "      shuffle: Boolean. If true, the strings are randomly shuffled within each\n",
      "        epoch.\n",
      "      seed: An integer (optional). Seed used if shuffle == True.\n",
      "      capacity: An integer. Sets the queue capacity.\n",
      "      shared_name: (optional). If set, this queue will be shared under the given\n",
      "        name across multiple sessions. All sessions open to the device which has\n",
      "        this queue will be able to access it via the shared_name. Using this in\n",
      "        a distributed setting means each name will only be seen by one of the\n",
      "        sessions which has access to this operation.\n",
      "      name: A name for the operations (optional).\n",
      "      cancel_op: Cancel op for the queue (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A queue with the output strings.  A `QueueRunner` for the Queue\n",
      "      is added to the current `Graph`'s `QUEUE_RUNNER` collection.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If the string_tensor is a null Python list.  At runtime,\n",
      "      will fail with an assertion if string_tensor becomes a null tensor.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 扩展资料\n",
    "\n",
    "原问题和数据集来源\n",
    "https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n",
    "kaggle提供了data，不过好像数据不算很好，有一个微软标注的FERPlus数据集可以做代替。\n",
    "\n",
    "这个代码来源\n",
    "https://github.com/elf-G/fer2013\n",
    "    \n",
    "扩展数据来源\n",
    "https://github.com/Microsoft/FERPlus\n",
    "\n",
    "\n",
    "原问题的讨论：\n",
    "很多铜牌发言，拿到奖金的也是华人\n",
    "https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
